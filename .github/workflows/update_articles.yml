name: Fetch News Articles

on:
  schedule:
    - cron: "0 * * * *" # runs hourly
  workflow_dispatch:

jobs:
  fetch:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.x'

      - name: Install deps
        run: pip install feedparser

      - name: Fetch RSS
        run: |
          import json, os, feedparser, re, hashlib

          FEEDS = [
                  "https://feeds.bbci.co.uk/news/rss.xml",
                  "https://feedx.net/rss/ap.xml",
                  "https://www.euronews.com/rss",
                  "https://time.com/feed/",
                  "https://rss.nytimes.com/services/xml/rss/nyt/HomePage.xml",
                  "https://www.cbc.ca/webfeed/rss/rss-topstories",
                  "https://globalnews.ca/feed/",
                  "https://www.aljazeera.com/xml/rss/all.xml",
                  "https://www.npr.org/rss/rss.php?id=1001",
                  "https://reliefweb.int/updates/rss.xml",
                  "https://www.odditycentral.com/feed",
                  "https://www.huffpost.com/section/weird-news/feed",
          ]
          KEYWORDS = ["murder", "death", "killed", "deceased", "hurricane", "earthquake", "tornado", "disaster", "crash", "attack", "war", "conflict", "explosion", "fire", "flood", "eruption", "tsunami", "pandemic", "outbreak", "epidemic", "disease", "injured", "hostage", "abducted", "assault", "robbery", "theft", "fraud", "scandal", "corruption", "bribery", "embezzlement", "extortion", "blackmail", "cyberattack", "hacking", "data breach", "espionage", "terrorism", "bombing", "guns", "massacre", "firearm", "shooting", "assassination", "disease", "depression", "death toll", "fatalities", "casualties", "evacuation", "crisis", "emergency", "aid", "victim"]

          articles_path = "articles.json"

          # Load existing articles
          if os.path.exists(articles_path):
              with open(articles_path, "r") as f:
                  try:
                      articles = json.load(f)
                  except:
                      articles = []
          else:
              articles = []

          existing_links = {a["link"] for a in articles}

          new_articles = []
          for url in FEEDS:
              feed = feedparser.parse(url)
              for entry in feed.entries:
                  text = (entry.title + " " + getattr(entry, "summary", "")).lower()
                  if any(kw.lower() in text for kw in KEYWORDS):
                      if entry.link not in existing_links:
                          new_articles.append({
                              "title": entry.title,
                              "link": entry.link,
                              "shown": False
                          })

          # Append new ones
          if new_articles:
              articles.extend(new_articles)
              with open(articles_path, "w") as f:
                  json.dump(articles, f, indent=2)

      - name: Commit changes
        run: |
          git config --global user.name "github-actions"
          git config --global user.email "github-actions@github.com"
          git add articles.json
          git commit -m "Update articles.json" || echo "No changes"
          git push
